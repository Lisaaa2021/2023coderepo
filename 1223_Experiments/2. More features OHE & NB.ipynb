{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fDB5AYSl52cp"
      },
      "outputs": [],
      "source": [
        "from util.ner_machine_learning import extract_embeddings_as_features_and_gold, \\\n",
        "    extract_features_and_labels, create_classifier\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import ComplementNB, GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB\n",
        "from sklearn.svm import SVC\n",
        "from util.feature_extract import extract_left_token, extract_right_token\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "#conll filepath\n",
        "train_path = '../data/conll2003.train.conll'\n",
        "dev_path = '../data/conll2003.dev.conll'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V13kB1gC52cq"
      },
      "outputs": [],
      "source": [
        "# Load the training data\n",
        "data = pd.read_csv(train_path, delimiter='\\t', quotechar= '|', header = None)\n",
        "data = data.rename({0:'token', 1:'pos', 2:'chunk_tag',3:'target'}, axis = 1)\n",
        "# [row, column]\n",
        "X_train = data[['token','pos','chunk_tag']]\n",
        "Y_train = data['target']\n",
        "#print(Y_train)\n",
        "\n",
        "# Load the test data\n",
        "data = pd.read_csv(dev_path, delimiter='\\t', quotechar='|', header=None)\n",
        "data = data.rename({0: 'token', 1: 'pos', 2: 'chunk_tag', 3: 'target'}, axis=1)\n",
        "X_dev = data[['token', 'pos', 'chunk_tag']]\n",
        "Y_dev = data['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RRc4RRl652cr"
      },
      "outputs": [],
      "source": [
        "# add token in the left to features\n",
        "X_train['token_left'] = extract_left_token(X_train['token'])\n",
        "X_dev['token_left'] = extract_left_token(X_dev['token'])\n",
        "\n",
        "X_train['token_right'] = extract_right_token(X_train['token'])\n",
        "X_dev['token_right'] = extract_right_token(X_dev['token'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RdxoD9wM52cr"
      },
      "outputs": [],
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "# When an unknown category is encountered during transform,\n",
        "# the resulting one-hot encoded columns for this feature will be all zeros.\n",
        "\n",
        "enc.fit_transform(X_train)\n",
        "X_train_ohe = enc.transform(X_train)\n",
        "X_dev_ohe = enc.transform(X_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7E2dJeb52cr"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C_sJlG9652cs",
        "outputId": "53717cb2-5a0e-4125-8044-af53badb0ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.873     0.834     0.853      1837\n",
            "      B-MISC      0.916     0.736     0.817       922\n",
            "       B-ORG      0.861     0.723     0.786      1341\n",
            "       B-PER      0.848     0.870     0.859      1842\n",
            "       I-LOC      0.902     0.720     0.801       257\n",
            "      I-MISC      0.904     0.624     0.738       346\n",
            "       I-ORG      0.817     0.690     0.748       751\n",
            "       I-PER      0.834     0.937     0.883      1307\n",
            "           O      0.983     0.995     0.989     42759\n",
            "\n",
            "    accuracy                          0.964     51362\n",
            "   macro avg      0.882     0.792     0.830     51362\n",
            "weighted avg      0.963     0.964     0.962     51362\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logreg = LogisticRegression(max_iter=100000)\n",
        "model = logreg.fit(X_train_ohe, Y_train)\n",
        "Y_pred = model.predict(X_dev_ohe)\n",
        "logreg_rpt = classification_report(Y_dev, Y_pred, digits = 3)\n",
        "print(logreg_rpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyRBOSpK52cs"
      },
      "source": [
        "### Naive Bayes\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "- Gaussian Naive Bayes\n",
        "- Multinomial Naive Bayes\n",
        "- Complement Naive Bayes\n",
        "- Bernoulli Naive Bayes\n",
        "- Categorical Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nYHpvgQN52ct"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for the 0 Naive Bayes model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.679     0.898     0.773      1837\n",
            "      B-MISC      0.691     0.785     0.735       922\n",
            "       B-ORG      0.754     0.701     0.727      1341\n",
            "       B-PER      0.852     0.789     0.819      1842\n",
            "       I-LOC      0.717     0.650     0.682       257\n",
            "      I-MISC      0.719     0.555     0.626       346\n",
            "       I-ORG      0.662     0.589     0.623       751\n",
            "       I-PER      0.761     0.881     0.817      1307\n",
            "           O      0.989     0.978     0.984     42759\n",
            "\n",
            "    accuracy                          0.945     51362\n",
            "   macro avg      0.758     0.758     0.754     51362\n",
            "weighted avg      0.948     0.945     0.946     51362\n",
            "\n",
            "------------------\n",
            "\n",
            "for the 1 Naive Bayes model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.750     0.857     0.800      1837\n",
            "      B-MISC      0.898     0.600     0.719       922\n",
            "       B-ORG      0.837     0.601     0.700      1341\n",
            "       B-PER      0.927     0.701     0.799      1842\n",
            "       I-LOC      0.882     0.233     0.369       257\n",
            "      I-MISC      1.000     0.275     0.431       346\n",
            "       I-ORG      0.754     0.570     0.649       751\n",
            "       I-PER      0.883     0.806     0.843      1307\n",
            "           O      0.959     0.995     0.977     42759\n",
            "\n",
            "    accuracy                          0.943     51362\n",
            "   macro avg      0.877     0.627     0.698     51362\n",
            "weighted avg      0.941     0.943     0.938     51362\n",
            "\n",
            "------------------\n",
            "\n",
            "for the 2 Naive Bayes model:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lisa2021/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.813     0.658     0.727      1837\n",
            "      B-MISC      0.000     0.000     0.000       922\n",
            "       B-ORG      0.849     0.248     0.383      1341\n",
            "       B-PER      0.928     0.419     0.577      1842\n",
            "       I-LOC      0.000     0.000     0.000       257\n",
            "      I-MISC      0.000     0.000     0.000       346\n",
            "       I-ORG      1.000     0.013     0.026       751\n",
            "       I-PER      0.992     0.277     0.433      1307\n",
            "           O      0.885     1.000     0.939     42759\n",
            "\n",
            "    accuracy                          0.885     51362\n",
            "   macro avg      0.608     0.290     0.343     51362\n",
            "weighted avg      0.862     0.885     0.850     51362\n",
            "\n",
            "------------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lisa2021/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/lisa2021/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Complement Naive Bayes\n",
        "models = [ComplementNB(), MultinomialNB(), BernoulliNB()]\n",
        "for ind, nb_model in enumerate(models):\n",
        "    print(f'for the {ind} Naive Bayes model:')\n",
        "    model = nb_model.fit(X_train_ohe, Y_train)\n",
        "    Y_pred = model.predict(X_dev_ohe)\n",
        "    cnb_rpt = classification_report(Y_dev, Y_pred, digits = 3)\n",
        "    print(cnb_rpt)\n",
        "    print('------------------')\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for the 0 Naive Bayes model:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lisa2021/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# models = [GaussianNB() ,CategoricalNB()]\n",
        "# for ind, nb_model in enumerate(models):\n",
        "#     print(f'for the {ind} Naive Bayes model:')\n",
        "#     model = nb_model.fit(X_train_ohe.todense(), Y_train)\n",
        "#     Y_pred = model.predict(X_dev_ohe.todense())\n",
        "#     cnb_rpt = classification_report(Y_dev, Y_pred)\n",
        "#     print(cnb_rpt)\n",
        "#     print('------------------')\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhcGzZw-52ct"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sKDwLwmf52ct",
        "outputId": "e4db53bb-9f51-4e1f-8d9f-e0c2e25e5c82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lisa2021/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.835     0.812     0.824      1837\n",
            "      B-MISC      0.930     0.682     0.787       922\n",
            "       B-ORG      0.836     0.698     0.761      1341\n",
            "       B-PER      0.791     0.834     0.812      1842\n",
            "       I-LOC      0.914     0.700     0.793       257\n",
            "      I-MISC      0.955     0.607     0.742       346\n",
            "       I-ORG      0.798     0.674     0.731       751\n",
            "       I-PER      0.706     0.947     0.809      1307\n",
            "           O      0.986     0.992     0.989     42759\n",
            "\n",
            "    accuracy                          0.957     51362\n",
            "   macro avg      0.861     0.772     0.805     51362\n",
            "weighted avg      0.958     0.957     0.956     51362\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#if number of features << number of training examples Gaussian kernel SVM\n",
        "\n",
        "\n",
        "svc_clf = SVC(kernel='rbf', max_iter = 10000)\n",
        "model = svc_clf.fit(X_train_ohe, Y_train)\n",
        "Y_pred = model.predict(X_dev_ohe)\n",
        "svc_rpt = classification_report(Y_dev, Y_pred, digits = 3)\n",
        "print(svc_rpt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IjUqYd6f52cu",
        "outputId": "57271366-2003-462e-d433-6abc41ab6029"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42.971350</td>\n",
              "      <td>4.697416</td>\n",
              "      <td>0.697998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.976553</td>\n",
              "      <td>4.825301</td>\n",
              "      <td>0.613402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47.433181</td>\n",
              "      <td>4.913506</td>\n",
              "      <td>0.714026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.115172</td>\n",
              "      <td>4.713499</td>\n",
              "      <td>0.679762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45.271179</td>\n",
              "      <td>4.663950</td>\n",
              "      <td>0.560522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fit_time  score_time  test_score\n",
              "0  42.971350    4.697416    0.697998\n",
              "1  44.976553    4.825301    0.613402\n",
              "2  47.433181    4.913506    0.714026\n",
              "3  48.115172    4.713499    0.679762\n",
              "4  45.271179    4.663950    0.560522"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Instantiate model\n",
        "model = SVC(kernel='rbf', max_iter=10000)\n",
        "cv_results = cross_validate(model, X_dev_ohe, Y_dev, cv=5, scoring='f1_macro')\n",
        "pd.DataFrame(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NLC4Fr5k52cu"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# # Hyperparameter tuning\n",
        "# # https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv/\n",
        "\n",
        "# #Instanciate model\n",
        "# model = SVC()\n",
        "\n",
        "# #Hyperparameter Grid\n",
        "# paras = {'C':[0.1, 1, 10, 100], 'kernel':['linear','poly','rbf','sigmoid','precomputed'],'gamma' :[1, 0.1, 0.01, 0.001]}\n",
        "\n",
        "# search = GridSearchCV(model, paras, scoring='f1_weighted', verbose = 2 , cv = 5)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b404d2aafdf561b3056e6883553e066f5a70fc5deb88f06afbbb68722dddb5be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
