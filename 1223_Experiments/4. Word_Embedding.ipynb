{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.ner_machine_learning import extract_embeddings_as_features_and_gold, \\\n",
    "    extract_features_and_labels, create_classifier\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import pandas as pd\n",
    "\n",
    "#conll filepath\n",
    "train_path = '../data/conll2003.train.conll'\n",
    "dev_path = '../data/conll2003.dev.conll'\n",
    "\n",
    "#word2vec binary filepath\n",
    "google_news = '../data/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "data = pd.read_csv(train_path, delimiter='\\t', quotechar='|', header=None)\n",
    "data = data.rename({0: 'token', 1: 'pos', 2: 'chunk_tag', 3: 'target'}, axis=1)\n",
    "# [row, column]\n",
    "X_train = data[['token', 'pos', 'chunk_tag']]\n",
    "Y_train = data['target']\n",
    "#print(Y_train)\n",
    "\n",
    "# Load the dev data\n",
    "data = pd.read_csv(dev_path, delimiter='\\t', quotechar='|', header=None)\n",
    "data = data.rename({0: 'token', 1: 'pos', 2: 'chunk_tag', 3: 'target'}, axis=1)\n",
    "X_dev = data[['token', 'pos', 'chunk_tag']]\n",
    "Y_dev = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the binary model\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(google_news, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word):\n",
    "    if word in wv_from_bin:\n",
    "        result = wv_from_bin[word]\n",
    "    else:\n",
    "        result = [0] * 300\n",
    "    return result\n",
    "\n",
    "\n",
    "X_train = list(X_train['token'].apply(word2vec))\n",
    "X_dev = list(X_dev['token'].apply(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# Combining token embedding and one hot encoder into one vector\n",
    "# ohe2 = OneHotEncoder(sparse=False)\n",
    "# X_train_ohe = ohe2.fit_transform(X_train[['pos', 'chunk_tag']])\n",
    "# ohe_word_embedding = pd.concat(\n",
    "#     [pd.DataFrame(X_train_ohe), X_train['token_embedding']], axis=1)\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.831     0.825     0.828      1837\n",
      "      B-MISC      0.803     0.704     0.750       922\n",
      "       B-ORG      0.688     0.660     0.674      1341\n",
      "       B-PER      0.781     0.710     0.744      1842\n",
      "       I-LOC      0.596     0.545     0.569       257\n",
      "      I-MISC      0.720     0.439     0.546       346\n",
      "       I-ORG      0.586     0.414     0.485       751\n",
      "       I-PER      0.617     0.578     0.597      1307\n",
      "           O      0.977     0.995     0.986     42759\n",
      "\n",
      "    accuracy                          0.940     51362\n",
      "   macro avg      0.733     0.652     0.687     51362\n",
      "weighted avg      0.936     0.940     0.937     51362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 100000)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_dev)\n",
    "logreg_rpt = classification_report(Y_dev, Y_pred, digits = 3)\n",
    "print(logreg_rpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b404d2aafdf561b3056e6883553e066f5a70fc5deb88f06afbbb68722dddb5be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
